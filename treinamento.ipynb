{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imagens</th>\n",
       "      <th>solucao</th>\n",
       "      <th>caminho_imagem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>226md.png</td>\n",
       "      <td>226md</td>\n",
       "      <td>samples\\226md.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22d5n.png</td>\n",
       "      <td>22d5n</td>\n",
       "      <td>samples\\22d5n.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2356g.png</td>\n",
       "      <td>2356g</td>\n",
       "      <td>samples\\2356g.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23mdg.png</td>\n",
       "      <td>23mdg</td>\n",
       "      <td>samples\\23mdg.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23n88.png</td>\n",
       "      <td>23n88</td>\n",
       "      <td>samples\\23n88.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1035</th>\n",
       "      <td>yx2d4.png</td>\n",
       "      <td>yx2d4</td>\n",
       "      <td>samples\\yx2d4.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1036</th>\n",
       "      <td>yxd7m.png</td>\n",
       "      <td>yxd7m</td>\n",
       "      <td>samples\\yxd7m.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1037</th>\n",
       "      <td>yy824.png</td>\n",
       "      <td>yy824</td>\n",
       "      <td>samples\\yy824.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1038</th>\n",
       "      <td>yyg5g.png</td>\n",
       "      <td>yyg5g</td>\n",
       "      <td>samples\\yyg5g.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1039</th>\n",
       "      <td>yyn57.png</td>\n",
       "      <td>yyn57</td>\n",
       "      <td>samples\\yyn57.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1040 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        imagens solucao     caminho_imagem\n",
       "0     226md.png   226md  samples\\226md.png\n",
       "1     22d5n.png   22d5n  samples\\22d5n.png\n",
       "2     2356g.png   2356g  samples\\2356g.png\n",
       "3     23mdg.png   23mdg  samples\\23mdg.png\n",
       "4     23n88.png   23n88  samples\\23n88.png\n",
       "...         ...     ...                ...\n",
       "1035  yx2d4.png   yx2d4  samples\\yx2d4.png\n",
       "1036  yxd7m.png   yxd7m  samples\\yxd7m.png\n",
       "1037  yy824.png   yy824  samples\\yy824.png\n",
       "1038  yyg5g.png   yyg5g  samples\\yyg5g.png\n",
       "1039  yyn57.png   yyn57  samples\\yyn57.png\n",
       "\n",
       "[1040 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "lista_imagens = list(i for i in os.listdir(r'samples') if i.endswith('.png'))\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'imagens': lista_imagens\n",
    "})\n",
    "df['solucao'] = df['imagens'].apply(lambda x: os.path.splitext(x)[0])\n",
    "df['caminho_imagem'] = df['imagens'].apply(lambda x: os.path.join('samples',x))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "altura = 100\n",
    "largura = 100\n",
    "\n",
    "\n",
    "def load_images(file_paths):\n",
    "    images = []\n",
    "    for path in file_paths:\n",
    "        image = Image.open(path).convert('RGB')\n",
    "        image = image.resize((altura, largura))\n",
    "        image = np.array(image) / 255.0\n",
    "        images.append(image)\n",
    "    return np.array(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = load_images(df['caminho_imagem'])\n",
    "\n",
    "y = df['solucao'].apply(list)\n",
    "\n",
    "characters = set(char for sublist in y for char in sublist)\n",
    "num_classes = len(characters)\n",
    "\n",
    "char_to_index = {char: i for i, char in enumerate(characters)}\n",
    "index_to_char = {i: char for char, i in char_to_index.items()}\n",
    "\n",
    "y = [[char_to_index[char] for char in sublist] for sublist in y]\n",
    "\n",
    "max_length = max(len(sublist) for sublist in y)\n",
    "y = tf.keras.preprocessing.sequence.pad_sequences(y, maxlen=max_length, padding='post')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 868ms/step - accuracy: 0.0977 - loss: 2.9774 - val_accuracy: 0.0971 - val_loss: 2.9273\n",
      "Epoch 2/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 595ms/step - accuracy: 0.0973 - loss: 2.9166 - val_accuracy: 0.0971 - val_loss: 2.8977\n",
      "Epoch 3/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 620ms/step - accuracy: 0.1198 - loss: 2.8355 - val_accuracy: 0.1019 - val_loss: 2.8266\n",
      "Epoch 4/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 584ms/step - accuracy: 0.1610 - loss: 2.7384 - val_accuracy: 0.1519 - val_loss: 2.7245\n",
      "Epoch 5/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 621ms/step - accuracy: 0.2180 - loss: 2.5741 - val_accuracy: 0.1663 - val_loss: 2.6873\n",
      "Epoch 6/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 612ms/step - accuracy: 0.2370 - loss: 2.4566 - val_accuracy: 0.2038 - val_loss: 2.5531\n",
      "Epoch 7/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 608ms/step - accuracy: 0.2698 - loss: 2.3087 - val_accuracy: 0.2106 - val_loss: 2.4751\n",
      "Epoch 8/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 625ms/step - accuracy: 0.2892 - loss: 2.1531 - val_accuracy: 0.2163 - val_loss: 2.4190\n",
      "Epoch 9/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 676ms/step - accuracy: 0.3099 - loss: 2.0273 - val_accuracy: 0.2356 - val_loss: 2.3783\n",
      "Epoch 10/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 594ms/step - accuracy: 0.3314 - loss: 1.9308 - val_accuracy: 0.2596 - val_loss: 2.3455\n",
      "Epoch 11/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 590ms/step - accuracy: 0.3384 - loss: 1.8434 - val_accuracy: 0.2654 - val_loss: 2.3208\n",
      "Epoch 12/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 577ms/step - accuracy: 0.3600 - loss: 1.7730 - val_accuracy: 0.2837 - val_loss: 2.2924\n",
      "Epoch 13/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 609ms/step - accuracy: 0.3743 - loss: 1.6754 - val_accuracy: 0.2846 - val_loss: 2.2715\n",
      "Epoch 14/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 563ms/step - accuracy: 0.3806 - loss: 1.6280 - val_accuracy: 0.2875 - val_loss: 2.2638\n",
      "Epoch 15/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 596ms/step - accuracy: 0.4089 - loss: 1.5617 - val_accuracy: 0.2952 - val_loss: 2.2352\n",
      "Epoch 16/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 583ms/step - accuracy: 0.4248 - loss: 1.5116 - val_accuracy: 0.3087 - val_loss: 2.2277\n",
      "Epoch 17/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 583ms/step - accuracy: 0.4427 - loss: 1.4622 - val_accuracy: 0.3048 - val_loss: 2.2169\n",
      "Epoch 18/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 588ms/step - accuracy: 0.4679 - loss: 1.4079 - val_accuracy: 0.3183 - val_loss: 2.2151\n",
      "Epoch 19/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 571ms/step - accuracy: 0.5006 - loss: 1.3564 - val_accuracy: 0.3260 - val_loss: 2.2193\n",
      "Epoch 20/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 587ms/step - accuracy: 0.5115 - loss: 1.3258 - val_accuracy: 0.3317 - val_loss: 2.2233\n",
      "Epoch 21/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 587ms/step - accuracy: 0.5246 - loss: 1.2969 - val_accuracy: 0.3250 - val_loss: 2.2180\n",
      "Epoch 22/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 584ms/step - accuracy: 0.5329 - loss: 1.2680 - val_accuracy: 0.3260 - val_loss: 2.2297\n",
      "Epoch 23/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 450ms/step - accuracy: 0.5438 - loss: 1.2380 - val_accuracy: 0.3462 - val_loss: 2.2141\n",
      "Epoch 24/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 608ms/step - accuracy: 0.5558 - loss: 1.2175 - val_accuracy: 0.3413 - val_loss: 2.2288\n",
      "Epoch 25/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 586ms/step - accuracy: 0.5806 - loss: 1.1949 - val_accuracy: 0.3365 - val_loss: 2.2273\n",
      "Epoch 26/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 458ms/step - accuracy: 0.5815 - loss: 1.1628 - val_accuracy: 0.3577 - val_loss: 2.2414\n",
      "Epoch 27/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 593ms/step - accuracy: 0.5977 - loss: 1.1319 - val_accuracy: 0.3529 - val_loss: 2.2418\n",
      "Epoch 28/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 587ms/step - accuracy: 0.6180 - loss: 1.1008 - val_accuracy: 0.3548 - val_loss: 2.2489\n",
      "Epoch 29/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 591ms/step - accuracy: 0.6351 - loss: 1.0764 - val_accuracy: 0.3500 - val_loss: 2.2487\n",
      "Epoch 30/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 561ms/step - accuracy: 0.6445 - loss: 1.0578 - val_accuracy: 0.3625 - val_loss: 2.2430\n",
      "Epoch 31/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 606ms/step - accuracy: 0.6591 - loss: 1.0222 - val_accuracy: 0.3635 - val_loss: 2.2136\n",
      "Epoch 32/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 585ms/step - accuracy: 0.6797 - loss: 0.9991 - val_accuracy: 0.3673 - val_loss: 2.2381\n",
      "Epoch 33/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 585ms/step - accuracy: 0.6813 - loss: 0.9801 - val_accuracy: 0.3654 - val_loss: 2.2117\n",
      "Epoch 34/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 588ms/step - accuracy: 0.6962 - loss: 0.9497 - val_accuracy: 0.3587 - val_loss: 2.2461\n",
      "Epoch 35/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 607ms/step - accuracy: 0.7051 - loss: 0.9265 - val_accuracy: 0.3673 - val_loss: 2.2191\n",
      "Epoch 36/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 598ms/step - accuracy: 0.7192 - loss: 0.9102 - val_accuracy: 0.3702 - val_loss: 2.2441\n",
      "Epoch 37/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 585ms/step - accuracy: 0.7102 - loss: 0.8959 - val_accuracy: 0.3750 - val_loss: 2.2138\n",
      "Epoch 38/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 608ms/step - accuracy: 0.7151 - loss: 0.8808 - val_accuracy: 0.3837 - val_loss: 2.2590\n",
      "Epoch 39/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 584ms/step - accuracy: 0.7300 - loss: 0.8646 - val_accuracy: 0.3808 - val_loss: 2.2444\n",
      "Epoch 40/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 573ms/step - accuracy: 0.7414 - loss: 0.8407 - val_accuracy: 0.3827 - val_loss: 2.2271\n",
      "Epoch 41/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 462ms/step - accuracy: 0.7586 - loss: 0.8221 - val_accuracy: 0.3894 - val_loss: 2.2186\n",
      "Epoch 42/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 399ms/step - accuracy: 0.7715 - loss: 0.7953 - val_accuracy: 0.3942 - val_loss: 2.2783\n",
      "Epoch 43/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 393ms/step - accuracy: 0.7651 - loss: 0.7872 - val_accuracy: 0.3923 - val_loss: 2.2281\n",
      "Epoch 44/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 398ms/step - accuracy: 0.7724 - loss: 0.7693 - val_accuracy: 0.4048 - val_loss: 2.2420\n",
      "Epoch 45/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 409ms/step - accuracy: 0.7939 - loss: 0.7470 - val_accuracy: 0.3971 - val_loss: 2.2214\n",
      "Epoch 46/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 397ms/step - accuracy: 0.7920 - loss: 0.7288 - val_accuracy: 0.4019 - val_loss: 2.1949\n",
      "Epoch 47/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 398ms/step - accuracy: 0.8007 - loss: 0.7161 - val_accuracy: 0.4058 - val_loss: 2.1934\n",
      "Epoch 48/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 396ms/step - accuracy: 0.8056 - loss: 0.6976 - val_accuracy: 0.4183 - val_loss: 2.2047\n",
      "Epoch 49/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 398ms/step - accuracy: 0.8179 - loss: 0.6757 - val_accuracy: 0.4173 - val_loss: 2.2048\n",
      "Epoch 50/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 400ms/step - accuracy: 0.8289 - loss: 0.6591 - val_accuracy: 0.4115 - val_loss: 2.2046\n",
      "Epoch 51/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 415ms/step - accuracy: 0.8604 - loss: 0.6298 - val_accuracy: 0.4221 - val_loss: 2.2189\n",
      "Epoch 52/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 396ms/step - accuracy: 0.8588 - loss: 0.6175 - val_accuracy: 0.4163 - val_loss: 2.2109\n",
      "Epoch 53/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 399ms/step - accuracy: 0.8541 - loss: 0.6038 - val_accuracy: 0.4125 - val_loss: 2.2174\n",
      "Epoch 54/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 402ms/step - accuracy: 0.8684 - loss: 0.5802 - val_accuracy: 0.4173 - val_loss: 2.2267\n",
      "Epoch 55/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 399ms/step - accuracy: 0.8609 - loss: 0.5783 - val_accuracy: 0.4058 - val_loss: 2.2381\n",
      "Epoch 56/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 399ms/step - accuracy: 0.8695 - loss: 0.5607 - val_accuracy: 0.4260 - val_loss: 2.1898\n",
      "Epoch 57/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 405ms/step - accuracy: 0.8793 - loss: 0.5400 - val_accuracy: 0.4077 - val_loss: 2.2353\n",
      "Epoch 58/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 400ms/step - accuracy: 0.8946 - loss: 0.5215 - val_accuracy: 0.4240 - val_loss: 2.2004\n",
      "Epoch 59/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 395ms/step - accuracy: 0.8993 - loss: 0.5117 - val_accuracy: 0.4212 - val_loss: 2.2034\n",
      "Epoch 60/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 404ms/step - accuracy: 0.8916 - loss: 0.5051 - val_accuracy: 0.4154 - val_loss: 2.2298\n",
      "Epoch 61/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 409ms/step - accuracy: 0.8931 - loss: 0.4812 - val_accuracy: 0.4288 - val_loss: 2.2643\n",
      "Epoch 62/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 398ms/step - accuracy: 0.9152 - loss: 0.4676 - val_accuracy: 0.4385 - val_loss: 2.2118\n",
      "Epoch 63/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 403ms/step - accuracy: 0.9170 - loss: 0.4428 - val_accuracy: 0.4404 - val_loss: 2.2020\n",
      "Epoch 64/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 398ms/step - accuracy: 0.9277 - loss: 0.4268 - val_accuracy: 0.4394 - val_loss: 2.2222\n",
      "Epoch 65/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 396ms/step - accuracy: 0.9334 - loss: 0.4100 - val_accuracy: 0.4240 - val_loss: 2.2305\n",
      "Epoch 66/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 400ms/step - accuracy: 0.9425 - loss: 0.3920 - val_accuracy: 0.4279 - val_loss: 2.2590\n",
      "Epoch 67/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 400ms/step - accuracy: 0.9527 - loss: 0.3725 - val_accuracy: 0.4356 - val_loss: 2.2429\n",
      "Epoch 68/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 418ms/step - accuracy: 0.9547 - loss: 0.3635 - val_accuracy: 0.4337 - val_loss: 2.2294\n",
      "Epoch 69/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 399ms/step - accuracy: 0.9506 - loss: 0.3572 - val_accuracy: 0.4356 - val_loss: 2.2543\n",
      "Epoch 70/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 402ms/step - accuracy: 0.9517 - loss: 0.3548 - val_accuracy: 0.4269 - val_loss: 2.3007\n",
      "Epoch 71/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 400ms/step - accuracy: 0.9528 - loss: 0.3439 - val_accuracy: 0.4385 - val_loss: 2.2560\n",
      "Epoch 72/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 396ms/step - accuracy: 0.9501 - loss: 0.3341 - val_accuracy: 0.4346 - val_loss: 2.2763\n",
      "Epoch 73/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 403ms/step - accuracy: 0.9590 - loss: 0.3122 - val_accuracy: 0.4356 - val_loss: 2.2677\n",
      "Epoch 74/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 399ms/step - accuracy: 0.9669 - loss: 0.2967 - val_accuracy: 0.4433 - val_loss: 2.2544\n",
      "Epoch 75/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 396ms/step - accuracy: 0.9739 - loss: 0.2792 - val_accuracy: 0.4413 - val_loss: 2.2573\n",
      "Epoch 76/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 395ms/step - accuracy: 0.9745 - loss: 0.2686 - val_accuracy: 0.4375 - val_loss: 2.2834\n",
      "Epoch 77/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 395ms/step - accuracy: 0.9763 - loss: 0.2628 - val_accuracy: 0.4288 - val_loss: 2.2960\n",
      "Epoch 78/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 407ms/step - accuracy: 0.9779 - loss: 0.2519 - val_accuracy: 0.4394 - val_loss: 2.2907\n",
      "Epoch 79/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 397ms/step - accuracy: 0.9793 - loss: 0.2459 - val_accuracy: 0.4404 - val_loss: 2.3177\n",
      "Epoch 80/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 396ms/step - accuracy: 0.9792 - loss: 0.2348 - val_accuracy: 0.4423 - val_loss: 2.3075\n",
      "Epoch 81/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 394ms/step - accuracy: 0.9818 - loss: 0.2203 - val_accuracy: 0.4413 - val_loss: 2.3088\n",
      "Epoch 82/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 399ms/step - accuracy: 0.9883 - loss: 0.2055 - val_accuracy: 0.4308 - val_loss: 2.3230\n",
      "Epoch 83/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 400ms/step - accuracy: 0.9891 - loss: 0.1996 - val_accuracy: 0.4365 - val_loss: 2.3270\n",
      "Epoch 84/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 404ms/step - accuracy: 0.9915 - loss: 0.1912 - val_accuracy: 0.4337 - val_loss: 2.3631\n",
      "Epoch 85/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 395ms/step - accuracy: 0.9906 - loss: 0.1813 - val_accuracy: 0.4385 - val_loss: 2.3340\n",
      "Epoch 86/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 401ms/step - accuracy: 0.9908 - loss: 0.1744 - val_accuracy: 0.4375 - val_loss: 2.3468\n",
      "Epoch 87/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 400ms/step - accuracy: 0.9900 - loss: 0.1699 - val_accuracy: 0.4385 - val_loss: 2.3711\n",
      "Epoch 88/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 404ms/step - accuracy: 0.9933 - loss: 0.1640 - val_accuracy: 0.4346 - val_loss: 2.3890\n",
      "Epoch 89/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 408ms/step - accuracy: 0.9901 - loss: 0.1598 - val_accuracy: 0.4365 - val_loss: 2.3704\n",
      "Epoch 90/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 397ms/step - accuracy: 0.9922 - loss: 0.1509 - val_accuracy: 0.4327 - val_loss: 2.3847\n",
      "Epoch 91/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 396ms/step - accuracy: 0.9901 - loss: 0.1462 - val_accuracy: 0.4385 - val_loss: 2.3971\n",
      "Epoch 92/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 397ms/step - accuracy: 0.9937 - loss: 0.1425 - val_accuracy: 0.4288 - val_loss: 2.4095\n",
      "Epoch 93/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 397ms/step - accuracy: 0.9933 - loss: 0.1346 - val_accuracy: 0.4269 - val_loss: 2.4240\n",
      "Epoch 94/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 402ms/step - accuracy: 0.9968 - loss: 0.1293 - val_accuracy: 0.4288 - val_loss: 2.3908\n",
      "Epoch 95/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 396ms/step - accuracy: 0.9933 - loss: 0.1266 - val_accuracy: 0.4279 - val_loss: 2.4333\n",
      "Epoch 96/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 398ms/step - accuracy: 0.9954 - loss: 0.1161 - val_accuracy: 0.4250 - val_loss: 2.4401\n",
      "Epoch 97/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 398ms/step - accuracy: 0.9973 - loss: 0.1127 - val_accuracy: 0.4288 - val_loss: 2.4434\n",
      "Epoch 98/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 397ms/step - accuracy: 0.9953 - loss: 0.1094 - val_accuracy: 0.4279 - val_loss: 2.4526\n",
      "Epoch 99/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 403ms/step - accuracy: 0.9957 - loss: 0.1075 - val_accuracy: 0.4183 - val_loss: 2.4573\n",
      "Epoch 100/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 398ms/step - accuracy: 0.9965 - loss: 0.1078 - val_accuracy: 0.4240 - val_loss: 2.4679\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.4122 - loss: 2.4611\n",
      "Test accuracy: 0.42403843998908997\n"
     ]
    }
   ],
   "source": [
    "# Definição do modelo seq2seq\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(altura, largura, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.Flatten(),\n",
    "    layers.RepeatVector(max_length),\n",
    "    layers.LSTM(64, return_sequences=True),\n",
    "    # layers.TimeDistributed(layers.Dense(num_classes, activation='softmax'))  # Camada densa para previsão de cada caractere\n",
    "    layers.Dense(num_classes, activation='softmax')  # Atualização da função de ativação para softmax\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=128, validation_data=(X_test, y_test))\n",
    "\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print('Test accuracy:', test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_captcha(model, captcha_image_path, char_to_index, index_to_char):\n",
    "    captcha_image = Image.open(captcha_image_path).convert('RGB')\n",
    "    captcha_image = captcha_image.resize((altura, largura))\n",
    "    captcha_image = np.array(captcha_image) / 255.0\n",
    "    captcha_image = np.expand_dims(captcha_image, axis=0) \n",
    "    \n",
    "    predictions = model.predict(captcha_image)\n",
    "    \n",
    "    decoded_predictions = []\n",
    "    for prediction in predictions[0]:\n",
    "        predicted_index = np.argmax(prediction)\n",
    "        predicted_char = index_to_char[predicted_index]\n",
    "        decoded_predictions.append(predicted_char)\n",
    "    \n",
    "    return ''.join(decoded_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "Predicted solution: 3fbxd\n"
     ]
    }
   ],
   "source": [
    "captcha_image_path = r'samples\\3fbxd.png'  \n",
    "predicted_solution = predict_captcha(model, captcha_image_path, char_to_index, index_to_char)\n",
    "print('Predicted solution:', predicted_solution)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('epochs_100_seq2seq.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Programação\\ml_captcha_image\\venv\\lib\\site-packages\\keras\\src\\saving\\saving_lib.py:418: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 13 variables whereas the saved optimizer has 24 variables. \n",
      "  trackable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Carregar o modelo\n",
    "modelo_carregado = load_model('epochs_100_seq2seq.keras')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('char_to_index.pickle', 'wb') as handle:\n",
    "    pickle.dump(char_to_index, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('index_to_char.pickle', 'wb') as handle:\n",
    "    pickle.dump(index_to_char, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('char_to_index.pickle', 'rb') as handle:\n",
    "    char_to_index_load = pickle.load(handle)\n",
    "\n",
    "with open('index_to_char.pickle', 'rb') as handle:\n",
    "    index_to_char_load = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step\n",
      "Predicted solution: 3fbxd\n"
     ]
    }
   ],
   "source": [
    "captcha_image_path = r'samples\\3fbxd.png'  \n",
    "predicted_solution = predict_captcha(modelo_carregado, captcha_image_path, char_to_index_load, index_to_char_load)\n",
    "print('Predicted solution:', predicted_solution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: montar .py para train e api"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
